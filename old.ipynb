{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfxktZJy95LW"
      },
      "source": [
        "### TRY"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests beautifulsoup4 networkx numpy scipy torch torchvision torchaudio torch-geometric\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__.split('+')[0])\")+.html\n"
      ],
      "metadata": {
        "id": "o-gpLj_StLua",
        "outputId": "f78bea0f-9962-4391-a855-dd5f60e4a3d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (1.14.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (4.13.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Looking in links: https://data.pyg.org/whl/torch-2.6.0+.html\n",
            "Collecting torch-scatter\n",
            "  Using cached torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-sparse\n",
            "  Using cached torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-cluster\n",
            "  Downloading torch_cluster-1.6.3.tar.gz (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-spline-conv\n",
            "  Downloading torch_spline_conv-1.2.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-sparse) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Building wheels for collected packages: torch-scatter, torch-sparse, torch-cluster, torch-spline-conv\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp311-cp311-linux_x86_64.whl size=547368 sha256=0b2c0fef08829aa93b23a76f6e4491e81b6d6fd96b8aeff64526fcbb15644e23\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/d4/0e/a80af2465354ea7355a2c153b11af2da739cfcf08b6c0b28e2\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp311-cp311-linux_x86_64.whl size=1127937 sha256=8935229e2f3c0bd4e4f795b5bfea1adc69ea0c7c7717e33a67dfa2fc18bb01ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/e2/1e/299c596063839303657c211f587f05591891cc6cf126d94d21\n",
            "  Building wheel for torch-cluster (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-cluster: filename=torch_cluster-1.6.3-cp311-cp311-linux_x86_64.whl size=739064 sha256=427cdc9980ecf99e42807c6dae9346390290d557767fd30d235e36fb513ddc4d\n",
            "  Stored in directory: /root/.cache/pip/wheels/ef/de/7d/a4211822af99147b93800e9e204f0be21294e3c0b95b3b861a\n",
            "  Building wheel for torch-spline-conv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-spline-conv: filename=torch_spline_conv-1.2.2-cp311-cp311-linux_x86_64.whl size=228695 sha256=880621814e222c01680883429cf135a4a2d4c13951d2c6e2493c40c55e5a537b\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/16/8a/a98b0173c4fbbc7aa1c4929b46d2eb08d1475c5c7b54e289b6\n",
            "Successfully built torch-scatter torch-sparse torch-cluster torch-spline-conv\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3 torch-scatter-2.1.2 torch-sparse-0.6.18 torch-spline-conv-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Import necessary libraries\n",
        "import requests\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from bs4 import BeautifulSoup\n",
        "from scipy.linalg import eigh\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_scatter import scatter_add\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "# Step 1: Robust Dataset Creation (Example)\n",
        "dataset = [\n",
        "    {\"name\": \"Pizza\", \"wikidata\": \"https://www.wikidata.org/wiki/Q177\", \"label\": 0},\n",
        "    {\"name\": \"Xiaolongbao\", \"wikidata\": \"https://www.wikidata.org/wiki/Q10943\", \"label\": 2},\n",
        "    {\"name\": \"Bauhaus Archive\", \"wikidata\": \"https://www.wikidata.org/wiki/Q811389\", \"label\": 1},\n",
        "]\n",
        "\n",
        "# Step 2: Enhanced Feature Extraction\n",
        "\n",
        "def robust_extract(soup, selector, default=None):\n",
        "    element = soup.select_one(selector)\n",
        "    return element.get_text(strip=True) if element else default\n",
        "\n",
        "def extract_features(url):\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    features = {}\n",
        "\n",
        "    # Wikidata statements\n",
        "    for stmt in soup.select('.wikibase-statementview'):\n",
        "        prop_label = robust_extract(stmt, '.wikibase-statementview-property-label')\n",
        "        value = robust_extract(stmt, '.wikibase-snakview-value')\n",
        "        if prop_label and value:\n",
        "            features[prop_label] = value\n",
        "\n",
        "    # Wikipedia extraction\n",
        "    enwiki_link = robust_extract(soup, 'a[title=\"English\"]', None)\n",
        "    if enwiki_link:\n",
        "        wiki_response = requests.get(enwiki_link['href'])\n",
        "        wiki_soup = BeautifulSoup(wiki_response.text, 'html.parser')\n",
        "\n",
        "        # Infobox extraction\n",
        "        for row in wiki_soup.select('.infobox tr'):\n",
        "            key = robust_extract(row, 'th')\n",
        "            val = robust_extract(row, 'td')\n",
        "            if key and val:\n",
        "                features[f\"infobox_{key}\"] = val\n",
        "\n",
        "        # Category extraction\n",
        "        categories = wiki_soup.select('#mw-normal-catlinks ul li')\n",
        "        features['categories'] = [cat.get_text(strip=True) for cat in categories]\n",
        "\n",
        "        # Article length\n",
        "        features['article_length'] = len(wiki_soup.select_one('body').get_text(strip=True))\n",
        "\n",
        "    return features\n",
        "\n",
        "# Multilingual embeddings extraction (recommended improvement)\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "model_emb = AutoModel.from_pretrained('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "def get_multilingual_embedding(texts):\n",
        "    encoded = tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        embeddings = model_emb(**encoded).last_hidden_state.mean(dim=1)\n",
        "    return embeddings.mean(dim=0).numpy()\n",
        "\n",
        "# Step 3: Graph Construction with extracted features\n",
        "\n",
        "def construct_graph(features):\n",
        "    G = nx.Graph()\n",
        "    node_mapping = {}  # maps node name (string) to numeric index (int)\n",
        "\n",
        "    # Create numeric nodes\n",
        "    for idx, (key, val) in enumerate(features.items()):\n",
        "        G.add_node(idx, feature=val, original_name=key)\n",
        "        node_mapping[key] = idx\n",
        "\n",
        "    # Add edges between numeric nodes\n",
        "    keys = list(features.keys())\n",
        "    for i in range(len(keys) - 1):\n",
        "        src_idx = node_mapping[keys[i]]\n",
        "        dst_idx = node_mapping[keys[i + 1]]\n",
        "        G.add_edge(src_idx, dst_idx)\n",
        "\n",
        "    return G, node_mapping\n",
        "\n",
        "\n",
        "\n",
        "# Step 4: Sheaf-based Positional Encodings\n",
        "def sheaf_pe(G, d=4):\n",
        "    A = nx.to_numpy_array(G)\n",
        "    D = np.diag(np.sum(A, axis=1))\n",
        "    L = D - A\n",
        "    eigvals, eigvecs = eigh(L)\n",
        "    return eigvecs[:, np.argsort(eigvals)[1:d+1]]\n",
        "\n",
        "# Step 5: Advanced SheafConvLayer (provided by user)\n",
        "class SheafConvLayer(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, edge_index, step_size=1.0):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.edge_index = edge_index\n",
        "        self.step_size = step_size\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "        self.sheaf_learner = nn.Linear(2 * input_dim, 1, bias=False)\n",
        "        self.register_buffer('left_idx', None)\n",
        "        self.register_buffer('right_idx', None)\n",
        "        self._precompute_indices()\n",
        "\n",
        "    def _precompute_indices(self):\n",
        "        edge_index = self.edge_index.cpu().numpy()\n",
        "        edge_dict = {(u, v): i for i, (u, v) in enumerate(zip(*edge_index))}\n",
        "        left_idx, right_idx = [], []\n",
        "        for i, (u, v) in enumerate(zip(*edge_index)):\n",
        "            left_idx.append(i)\n",
        "            rev_idx = edge_dict.get((v, u), i)\n",
        "            right_idx.append(rev_idx)\n",
        "        self.left_idx = torch.tensor(left_idx, dtype=torch.long)\n",
        "        self.right_idx = torch.tensor(right_idx, dtype=torch.long)\n",
        "\n",
        "    def predict_restriction_maps(self, x):\n",
        "        row, col = self.edge_index\n",
        "        x_row = x[row]\n",
        "        x_col = x[col]\n",
        "        maps = self.sheaf_learner(torch.cat([x_row, x_col], dim=1))\n",
        "        return torch.tanh(maps)\n",
        "\n",
        "    def build_laplacian(self, maps, num_nodes):\n",
        "        row, col = self.edge_index.to(maps.device)\n",
        "        left_maps = maps[self.left_idx]\n",
        "        right_maps = maps[self.right_idx]\n",
        "        non_diag = -left_maps * right_maps\n",
        "        diag = scatter_add(maps ** 2, row, dim=0, dim_size=num_nodes)\n",
        "        d_inv_sqrt = (diag + 1e-6).pow(-0.5)\n",
        "        left_norm = d_inv_sqrt[row]\n",
        "        right_norm = d_inv_sqrt[col]\n",
        "        norm_vals = left_norm * non_diag * right_norm\n",
        "        diag_vals = d_inv_sqrt * diag * d_inv_sqrt\n",
        "        diag_indices = torch.arange(num_nodes, device=maps.device).unsqueeze(0).repeat(2, 1)\n",
        "        all_indices = torch.cat([diag_indices, self.edge_index], dim=1)\n",
        "        all_values = torch.cat([diag_vals.view(-1), norm_vals.view(-1)])\n",
        "        return torch.sparse_coo_tensor(all_indices, all_values, size=(num_nodes, num_nodes))\n",
        "\n",
        "    def forward(self, x):\n",
        "        num_nodes = x.size(0)\n",
        "        device = x.device\n",
        "        self.edge_index = self.edge_index.to(device)\n",
        "        self.left_idx = self.left_idx.to(device)\n",
        "        self.right_idx = self.right_idx.to(device)\n",
        "        maps = self.predict_restriction_maps(x)\n",
        "        laplacian = self.build_laplacian(maps, num_nodes)\n",
        "        return self.linear(x) - self.step_size * torch.sparse.mm(laplacian, self.linear(x))\n",
        "# Step 6: SheafGNN Integration\n",
        "class SheafGNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim, edge_index):\n",
        "        super().__init__()\n",
        "        self.conv1 = SheafConvLayer(input_dim, hidden_dim, edge_index)\n",
        "        self.conv2 = SheafConvLayer(hidden_dim, hidden_dim, edge_index)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x, batch):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = global_mean_pool(x, batch)\n",
        "        return F.log_softmax(self.fc(x), dim=1)\n",
        "\n",
        "# Step 7: Data Preparation Pipeline (corrected)\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "data_list = []\n",
        "for item in dataset:\n",
        "    features = extract_features(item['wikidata'])\n",
        "    graph, node_mapping = construct_graph(features)\n",
        "\n",
        "    if graph.number_of_nodes() == 0:\n",
        "        # Skip empty graph\n",
        "        continue\n",
        "\n",
        "    pe = sheaf_pe(graph)\n",
        "    multilingual_emb = get_multilingual_embedding([item['name']])\n",
        "    multilingual_emb_expanded = np.tile(multilingual_emb, (pe.shape[0], 1))\n",
        "\n",
        "    x = torch.tensor(np.hstack([pe, multilingual_emb_expanded]), dtype=torch.float)\n",
        "\n",
        "    edges = list(graph.edges)\n",
        "    if len(edges) == 0:\n",
        "        # Add self-loop to ensure edge_index has valid dimensions\n",
        "        edges = [(0, 0)]\n",
        "\n",
        "    edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
        "    if edge_index.numel() == 0 or edge_index.dim() != 2 or edge_index.shape[0] != 2:\n",
        "        print(f\"⚠️ Skipping graph '{item['name']}' due to bad edge_index shape.\")\n",
        "        continue\n",
        "\n",
        "    y = torch.tensor([item['label']], dtype=torch.long)\n",
        "    batch = torch.zeros(x.size(0), dtype=torch.long)\n",
        "\n",
        "    data = Data(x=x, edge_index=edge_index, y=y, batch=batch)\n",
        "    data_list.append(data)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 8: Training Example (brief)\n",
        "loader = DataLoader(data_list, batch_size=2, shuffle=True)\n",
        "model = SheafGNN(input_dim=x.shape[1], hidden_dim=16, output_dim=3, edge_index=edge_index)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(30):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data in loader:\n",
        "        optimizer.zero_grad()\n",
        "        out = model(data.x, data.batch)\n",
        "        loss = F.nll_loss(out, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(loader):.4f}')\n"
      ],
      "metadata": {
        "id": "SNbrloqbs6j-",
        "outputId": "29973a39-871b-44fd-e8e4-ad9bbe8b8123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "num_samples should be a positive integer value, but got num_samples=0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-dbcbfb67ce37>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;31m# Step 8: Training Example (brief)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSheafGNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch_geometric/loader/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexclude_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexclude_keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         super().__init__(\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device, in_order)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# map-style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                     \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequentialSampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_samples\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    166\u001b[0m                 \u001b[0;34mf\"num_samples should be a positive integer value, but got num_samples={self.num_samples}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             )\n",
            "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}